{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 7.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "KqE6AZWjR4RW",
        "colab_type": "code",
        "outputId": "527f4f5d-5df8-44f5-eca2-9aceac45dd1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "htEoAIREQh6j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**1. Data Processing:** This data set is a bit messy, so the preprocessing portion is largely a tutorial to make sure students have data ready for keras. \n",
        "\n",
        "a) Import the following libraries: "
      ]
    },
    {
      "metadata": {
        "id": "9fH2FULROdsM",
        "colab_type": "code",
        "outputId": "0e4bdd41-e747-4eac-e70a-c04d2325a870",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import json\n",
        "import pandas\n",
        "import numpy\n",
        "import optparse\n",
        "\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from collections import OrderedDict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "rXLVQ6o7Qk6T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "b) We will read the code in slightly differently than before: "
      ]
    },
    {
      "metadata": {
        "id": "TpoCGPm9Qxiq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataframe = pandas.read_csv('/content/gdrive/My Drive/Machine Learning/Assignment 7/dev-access.csv', engine='python', quotechar='|', header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aXGMLfxFQ0Lk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "c) We then need to convert to a numpy.ndarray type: "
      ]
    },
    {
      "metadata": {
        "id": "KscK25mIQ0VR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset = dataframe.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m671fSCAQ6ym",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "d) Check the shape of the data set - it should be (26773, 2). Spend some time looking at the data. "
      ]
    },
    {
      "metadata": {
        "id": "W6t2p47tQ6-N",
        "colab_type": "code",
        "outputId": "457b6278-26a3-4e99-c9fa-3410ff1d6c13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "dataset.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26773, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "-Wq3s-vyTxHw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "e) Store all rows and the 0th index as the feature data: "
      ]
    },
    {
      "metadata": {
        "id": "cQnywYmETxTI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = dataset[:,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TY39J9bfT6zJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "f) Store all rows and index 1 as the target variable: "
      ]
    },
    {
      "metadata": {
        "id": "0MEOQjcuT682",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y = dataset[:,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D3Acu8p2UB6m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "g) In the next step, we will clean up the predictors. This includes removing features that are not valuable, such as timestamp and source. "
      ]
    },
    {
      "metadata": {
        "id": "yQte3DxoUCUX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for index, item in enumerate(X):\n",
        "# Quick hack to space out json elements\n",
        "  reqJson = json.loads(item, object_pairs_hook=OrderedDict)\n",
        "  del reqJson['timestamp']\n",
        "  del reqJson['headers']\n",
        "  del reqJson['source']\n",
        "  del reqJson['route']\n",
        "  del reqJson['responsePayload']\n",
        "  X[index] = json.dumps(reqJson, separators=(',', ':'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b5eJbuVpUMju",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "h) We next will tokenize our data, which just means vectorizing our text. Given the data we will tokenize every character (thus char_level = True)"
      ]
    },
    {
      "metadata": {
        "id": "Dl_8Fi2AUPdm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(filters='\\t\\n', char_level=True)\n",
        "tokenizer.fit_on_texts(X)\n",
        "\n",
        "# we will need this later\n",
        "num_words = len(tokenizer.word_index)+1\n",
        "X = tokenizer.texts_to_sequences(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wAAjWv2XUSj2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "i) Need to pad our data as each observation has a different length"
      ]
    },
    {
      "metadata": {
        "id": "EiCR1UKMUVve",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_log_length = 1024\n",
        "X_processed = sequence.pad_sequences(X, maxlen=max_log_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jhlUv1uWUaCc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "j) Create your train set to be 75% of the data and your test set to be 25%"
      ]
    },
    {
      "metadata": {
        "id": "V3oUXk9DYj5S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_processed, Y, test_size=0.25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KM5C1VceZtlJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**2. Model 1 - RNN:** The first model will be a pretty minimal RNN with only an embedding layer, LSTM layer, and Dense layer. The next model we will add a few more layers. \n",
        "\n",
        "a) Start by creating an instance of a Sequential model"
      ]
    },
    {
      "metadata": {
        "id": "lqYthIdcaRez",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "\n",
        "model = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_-e00LUaZ5h3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "b) From there, add an Embedding layer: \n",
        "\n",
        "Params:\n",
        "- input_dim = num_words (the variable we created above)\n",
        "- output_dim = 32\n",
        "- input_length = max_log_length (we also created this above) \n",
        "- Keep all other variables as the defaults (shown below)"
      ]
    },
    {
      "metadata": {
        "id": "SIwNxWXAaSIk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Embedding(input_dim = num_words, output_dim = 32, input_length=max_log_length))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6HSZxuisZ-6I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "c) Add an LSTM layer \n",
        "\n",
        "Params:\n",
        "- units = 64\n",
        "- recurrent_dropout=0.5"
      ]
    },
    {
      "metadata": {
        "id": "5mLceIc0aS0i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(LSTM(units=64,recurrent_dropout=0.5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GxnEFRZeaAsl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "d) Finally, we will add a Dense layer:\n",
        "\n",
        "Params:\n",
        "- units = 1 (this will be our output)\n",
        "- activation = relu"
      ]
    },
    {
      "metadata": {
        "id": "aLjloWysaTpu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Dense(units=1,activation='relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ncFo7XFraEYV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "e) Compile model using the .compile() method:\n",
        "\n",
        "Params:\n",
        "- loss = binary_crossentropy\n",
        "- optimizer = adam\n",
        "- metrics = accuracy"
      ]
    },
    {
      "metadata": {
        "id": "-dNsMQHBaUQf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CZ9gVa5DaITq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "f) Print the model summary"
      ]
    },
    {
      "metadata": {
        "id": "SHuLpJJbaVDe",
        "colab_type": "code",
        "outputId": "6cc5af14-2d05-4db4-e42e-47d02e7bfc48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 1024, 32)          2016      \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 64)                24832     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 26,913\n",
            "Trainable params: 26,913\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hQqlL7SkaKox",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "g) Use the .fit() method to fit the model on the train data. Use a validation split of 0.25, epochs=3 and batch size = 128."
      ]
    },
    {
      "metadata": {
        "id": "ynUGgVFgaVoU",
        "colab_type": "code",
        "outputId": "e079dcbf-3289-4819-e0b3-973557476b83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "model_fit = model.fit(X_train,y_train,epochs=3,batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "20079/20079 [==============================] - 254s 13ms/step - loss: 0.9321 - acc: 0.5292\n",
            "Epoch 2/3\n",
            "20079/20079 [==============================] - 251s 13ms/step - loss: 0.6217 - acc: 0.6098\n",
            "Epoch 3/3\n",
            "20079/20079 [==============================] - 252s 13ms/step - loss: 0.5783 - acc: 0.5844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KeCb9SYgaNJW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "h) Use the .evaluate() method to get the loss value & the accuracy value on the test data. Use a batch size of 128 again."
      ]
    },
    {
      "metadata": {
        "id": "6wDHkPjTaWVR",
        "colab_type": "code",
        "outputId": "49a1bbff-c7b5-430f-8f05-a1def6cad1b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, y_test, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6694/6694 [==============================] - 19s 3ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0997397zcDbY",
        "colab_type": "code",
        "outputId": "076868f4-685a-4a28-bdd7-b600c7000be8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Loss Value:\",score[0])\n",
        "print(\"Accuracy:\",score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss Value: 0.5585686050139508\n",
            "Accuracy: 0.5519868539613434\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Zddrsahlf5u-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**3) Model 2 - RNN + Dropout Layers + New Activation Function:**\n",
        "\n",
        "Now we will add a few new layers to our RNN and switch the activation function. You will be creating a new model here, so make sure to call it something different than the model from Part 2.\n",
        "\n",
        "a) This RNN needs to have the following layers (add in this order):\n",
        "\n",
        "- Embedding Layer (use same params as before)\n",
        "- Dropout Layer (https://keras.io/layers/core/#dropout (Links to an external site.)Links to an external site.) - use a value of 0.5 for now\n",
        "- LSTM Layer (use same params as before)\n",
        "- Dropout Layer - use a value of 0.5 \n",
        "- Dense Layer - (switch to a sigmoid activation function)"
      ]
    },
    {
      "metadata": {
        "id": "tQOW_OycwKwg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Embedding(input_dim = num_words, output_dim = 32, input_length=max_log_length))\n",
        "model2.add(Dropout(0.5))\n",
        "model2.add(LSTM(units=64,recurrent_dropout=0.5))\n",
        "model2.add(Dropout(0.5))\n",
        "model2.add(Dense(units=1,activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L95NprFTxM1R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "b) Compile model using the .compile() method:\n",
        "\n",
        "Params:\n",
        "- loss = binary_crossentropy\n",
        "- optimizer = adam\n",
        "- metrics = accuracy"
      ]
    },
    {
      "metadata": {
        "id": "uGLnL3CmxQ9F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model2.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sxYQO_9GxVvV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "c) Print the model summary"
      ]
    },
    {
      "metadata": {
        "id": "eNetHHgzxX7f",
        "colab_type": "code",
        "outputId": "87915cff-d02b-4539-86f8-6d959391175d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "cell_type": "code",
      "source": [
        "print(model2.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 1024, 32)          2016      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024, 32)          0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 64)                24832     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 26,913\n",
            "Trainable params: 26,913\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A2KDjRM3xcyP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "d) Use the .fit() method to fit the model on the train data. Use a validation split of 0.25, epochs=3 and batch size = 128"
      ]
    },
    {
      "metadata": {
        "id": "nfifclohxhsL",
        "colab_type": "code",
        "outputId": "0e2ec45c-7b32-480f-b6e4-2440414a0214",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "model2_fit = model2.fit(X_train,y_train,epochs=3,batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "20079/20079 [==============================] - 264s 13ms/step - loss: 0.5989 - acc: 0.6523\n",
            "Epoch 2/3\n",
            "20079/20079 [==============================] - 262s 13ms/step - loss: 0.3605 - acc: 0.8630\n",
            "Epoch 3/3\n",
            "20079/20079 [==============================] - 262s 13ms/step - loss: 0.3681 - acc: 0.8648\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dCnpzIMqxuG_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "e) Use the .evaluate() method to get the loss value & the accuracy value on the test data. Use a batch size of 128 again"
      ]
    },
    {
      "metadata": {
        "id": "hudSMb9fxx-U",
        "colab_type": "code",
        "outputId": "82c6ada5-32c3-4915-ea0a-cdbf72869d89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "score2 = model2.evaluate(X_test, y_test, batch_size=128)\n",
        "print(\"Loss Value:\",score2[0])\n",
        "print(\"Accuracy:\",score2[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6694/6694 [==============================] - 19s 3ms/step\n",
            "Loss Value: 0.2067657412166983\n",
            "Accuracy: 0.9403943829227285\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HmYMy-CAyD3h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**4) Recurrent Neural Net Model 3: Build Your Own**\n",
        "\n",
        "You wil now create your RNN based on what you have learned from Model 1 & Model 2:\n",
        "\n",
        "a) RNN Requirements: \n",
        "- Use 5 or more layers\n",
        "- Add a layer that was not utilized in Model 1 or Model 2 (Note: This could be a new Dense layer or an additional LSTM)"
      ]
    },
    {
      "metadata": {
        "id": "fpG8lFEWyHjf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Flatten\n",
        "model3 = Sequential()\n",
        "model3.add(Embedding(input_dim = num_words, output_dim = 32, input_length=max_log_length))\n",
        "model3.add(Dense(64,activation='relu'))\n",
        "model3.add(Dropout(0.5))\n",
        "model3.add(Dense(64,activation='relu'))\n",
        "model3.add(Dropout(0.5))\n",
        "model3.add(Flatten())\n",
        "model3.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u2i1Z4qVyKo9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "b) Compiler Requirements: \n",
        "- Try a new optimizer for the compile step\n",
        "- Keep accuracy as a metric (feel free to add more metrics if desired)"
      ]
    },
    {
      "metadata": {
        "id": "f9mc8hxLyQm2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model3.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uBUEf83_yQyj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "c) Print the model summary"
      ]
    },
    {
      "metadata": {
        "id": "f5g9fEimyVij",
        "colab_type": "code",
        "outputId": "d68c8d1a-7956-4421-f2e3-1083783c8c79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "cell_type": "code",
      "source": [
        "print(model3.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 1024, 32)          2016      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1024, 64)          2112      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1024, 64)          0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1024, 64)          4160      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 1024, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 65536)             0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 65537     \n",
            "=================================================================\n",
            "Total params: 73,825\n",
            "Trainable params: 73,825\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ya_wdrxcyWIW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "d) Use the .fit() method to fit the model on the train data. Use a validation split of 0.25, epochs=3 and batch size = 128."
      ]
    },
    {
      "metadata": {
        "id": "q0nFZetbyaNz",
        "colab_type": "code",
        "outputId": "2ef2616b-c6de-4184-adad-95174dadf944",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "model3_fit = model3.fit(X_train,y_train,epochs=3,batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "20079/20079 [==============================] - 67s 3ms/step - loss: 0.3651 - acc: 0.8351\n",
            "Epoch 2/3\n",
            "20079/20079 [==============================] - 67s 3ms/step - loss: 0.1156 - acc: 0.9577\n",
            "Epoch 3/3\n",
            "20079/20079 [==============================] - 67s 3ms/step - loss: 0.0565 - acc: 0.9814\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Rod_fh-CycVr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "e) Use the .evaluate() method to get the loss value & the accuracy value on the test data. Use a batch size of 128 again."
      ]
    },
    {
      "metadata": {
        "id": "pTZmUhPeyc86",
        "colab_type": "code",
        "outputId": "566690d0-266e-4041-c0e5-e8a5e68bf040",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "score3 = model3.evaluate(X_test, y_test, batch_size=128)\n",
        "print(\"Loss Value:\",score3[0])\n",
        "print(\"Accuracy:\",score3[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6694/6694 [==============================] - 5s 735us/step\n",
            "Loss Value: 0.03621236315903635\n",
            "Accuracy: 0.9855094114132058\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Mx4DqeSs3Wru",
        "colab_type": "code",
        "outputId": "07d9371c-45c8-484b-f99e-48d00caec726",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "X_train.max()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "nowdEbIL3GCJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Conceptual Questions:** \n",
        "\n",
        "**5) Explain the difference between the relu activation function and the sigmoid activation function. **\n",
        "\n",
        "The sigmoid function is nonlinear and bounded for 0 to 1 whereas the ReLU is 0 for all negative values and linear with a slope of one for positive values.\n",
        "\n",
        "**6) In regards to question 5, which of these activation functions performed the best (they were used in Model 1 & Model 2) ? Why do you think that is?**\n",
        "\n",
        "We see that Model 2 which involves sigmoid activation performs much better than Model 1 using ReLU activation. This makes sense that the sigmoid activation would more accurately predict the output because the output variable of our data is a predictor of 0 or 1 but the input value ranges from 0 to 62.\n",
        "\n",
        "**7) Explain how dropout works (you can look at the keras code) for (a) training, and (b) test data sets.**\n",
        "\n",
        "Dropout helps prevent overfitting the data by randomly leaving out certain neurons during the training of the model.\n",
        "\n",
        "**8) Explain why problems such as this are better modeled with RNNs than CNNs.**\n",
        "\n",
        "Convolutional Neural Networks are used primarily to map image data or problems working with spacial input values. An RNN Model is more relevent for this problem because is very effective for mapping sequentional data to predictions.\n",
        "\n",
        "**9) Explain what RNN problem is solved using LSTM and briefly describe how.**\n",
        "\n",
        "LSTMs are capable of modeling long term dependencies in the data. Therefore it can capture information that would have been left out of the original RNN model"
      ]
    },
    {
      "metadata": {
        "id": "K_6O9xTFBCSU",
        "colab_type": "code",
        "outputId": "667493bd-e5fe-42b9-c8b3-aa37d4057edb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert --to html '/content/gdrive/My Drive/Machine Learning/Assignment 7/Assignment 7.ipynb';"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[NbConvertApp] Converting notebook /content/gdrive/My Drive/Machine Learning/Assignment 7/Assignment 7.ipynb to html\n",
            "[NbConvertApp] Writing 326647 bytes to /content/gdrive/My Drive/Machine Learning/Assignment 7/Assignment 7.html\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}