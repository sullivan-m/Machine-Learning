{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "S6isRLwysRnH",
    "outputId": "a6bd6feb-fd66-4e95-9588-c876ebac4078"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kHGlzzL79oXn"
   },
   "source": [
    "**1. Data Processing:**\n",
    "\n",
    "a) Import the data: You are provided separate .csv files for train and test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gzOrxz3ts0jJ"
   },
   "outputs": [],
   "source": [
    "filepath = '/content/gdrive/My Drive/Machine Learning/Assignment 5/Urban land cover/'\n",
    "train_path = filepath + 'train_data.csv'\n",
    "test_path = filepath + 'test_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EHGb47Bbs1UO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "colab_type": "code",
    "id": "aEsvSgFas1cb",
    "outputId": "e79ea484-717a-4131-e9c9-8b66c07fded4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>BrdIndx</th>\n",
       "      <th>Area</th>\n",
       "      <th>Round</th>\n",
       "      <th>Bright</th>\n",
       "      <th>Compact</th>\n",
       "      <th>ShpIndx</th>\n",
       "      <th>Mean_G</th>\n",
       "      <th>Mean_R</th>\n",
       "      <th>Mean_NIR</th>\n",
       "      <th>...</th>\n",
       "      <th>SD_NIR_140</th>\n",
       "      <th>LW_140</th>\n",
       "      <th>GLCM1_140</th>\n",
       "      <th>Rect_140</th>\n",
       "      <th>GLCM2_140</th>\n",
       "      <th>Dens_140</th>\n",
       "      <th>Assym_140</th>\n",
       "      <th>NDVI_140</th>\n",
       "      <th>BordLngth_140</th>\n",
       "      <th>GLCM3_140</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>concrete</td>\n",
       "      <td>1.32</td>\n",
       "      <td>131</td>\n",
       "      <td>0.81</td>\n",
       "      <td>222.74</td>\n",
       "      <td>1.66</td>\n",
       "      <td>2.18</td>\n",
       "      <td>192.94</td>\n",
       "      <td>235.11</td>\n",
       "      <td>240.15</td>\n",
       "      <td>...</td>\n",
       "      <td>31.15</td>\n",
       "      <td>5.04</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.58</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.98</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>1512</td>\n",
       "      <td>1287.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shadow</td>\n",
       "      <td>1.59</td>\n",
       "      <td>864</td>\n",
       "      <td>0.94</td>\n",
       "      <td>47.56</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.87</td>\n",
       "      <td>36.82</td>\n",
       "      <td>48.78</td>\n",
       "      <td>57.09</td>\n",
       "      <td>...</td>\n",
       "      <td>12.01</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.96</td>\n",
       "      <td>7.01</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.86</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>196</td>\n",
       "      <td>2659.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shadow</td>\n",
       "      <td>1.41</td>\n",
       "      <td>409</td>\n",
       "      <td>1.00</td>\n",
       "      <td>51.38</td>\n",
       "      <td>1.37</td>\n",
       "      <td>1.53</td>\n",
       "      <td>41.72</td>\n",
       "      <td>51.96</td>\n",
       "      <td>60.48</td>\n",
       "      <td>...</td>\n",
       "      <td>18.75</td>\n",
       "      <td>3.09</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.63</td>\n",
       "      <td>8.32</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1198</td>\n",
       "      <td>720.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tree</td>\n",
       "      <td>2.58</td>\n",
       "      <td>187</td>\n",
       "      <td>1.91</td>\n",
       "      <td>70.08</td>\n",
       "      <td>3.41</td>\n",
       "      <td>3.11</td>\n",
       "      <td>93.13</td>\n",
       "      <td>55.20</td>\n",
       "      <td>61.92</td>\n",
       "      <td>...</td>\n",
       "      <td>27.67</td>\n",
       "      <td>6.33</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.70</td>\n",
       "      <td>8.56</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.20</td>\n",
       "      <td>524</td>\n",
       "      <td>891.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>asphalt</td>\n",
       "      <td>2.60</td>\n",
       "      <td>116</td>\n",
       "      <td>2.05</td>\n",
       "      <td>89.57</td>\n",
       "      <td>3.06</td>\n",
       "      <td>3.02</td>\n",
       "      <td>73.17</td>\n",
       "      <td>94.89</td>\n",
       "      <td>100.64</td>\n",
       "      <td>...</td>\n",
       "      <td>32.05</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8.62</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>496</td>\n",
       "      <td>1194.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       class  BrdIndx  Area  Round  Bright  Compact  ShpIndx  Mean_G  Mean_R  \\\n",
       "0  concrete      1.32   131   0.81  222.74     1.66     2.18  192.94  235.11   \n",
       "1    shadow      1.59   864   0.94   47.56     1.41     1.87   36.82   48.78   \n",
       "2    shadow      1.41   409   1.00   51.38     1.37     1.53   41.72   51.96   \n",
       "3      tree      2.58   187   1.91   70.08     3.41     3.11   93.13   55.20   \n",
       "4   asphalt      2.60   116   2.05   89.57     3.06     3.02   73.17   94.89   \n",
       "\n",
       "   Mean_NIR    ...      SD_NIR_140  LW_140  GLCM1_140  Rect_140  GLCM2_140  \\\n",
       "0    240.15    ...           31.15    5.04       0.80      0.58       8.56   \n",
       "1     57.09    ...           12.01    3.70       0.52      0.96       7.01   \n",
       "2     60.48    ...           18.75    3.09       0.90      0.63       8.32   \n",
       "3     61.92    ...           27.67    6.33       0.89      0.70       8.56   \n",
       "4    100.64    ...           32.05    1.01       0.83      0.75       8.62   \n",
       "\n",
       "   Dens_140  Assym_140  NDVI_140  BordLngth_140  GLCM3_140  \n",
       "0      0.82       0.98     -0.10           1512    1287.52  \n",
       "1      1.69       0.86     -0.14            196    2659.74  \n",
       "2      1.38       0.84      0.10           1198     720.38  \n",
       "3      1.10       0.96      0.20            524     891.36  \n",
       "4      2.08       0.08     -0.10            496    1194.76  \n",
       "\n",
       "[5 rows x 148 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QNZyQk1N9iX9"
   },
   "outputs": [],
   "source": [
    "# b) Remove any rows that have missing data across both sets of data\n",
    "train = train.dropna(how='any', axis = 0)\n",
    "test = test.dropna(how='any', axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v3ANiwkc-GEt"
   },
   "outputs": [],
   "source": [
    "#c) The target variable (dependent variable) is called \"class\", make sure to separate this out into a \"y_train\" and \"y_test\" and remove from your \"X_train\" and \"X_test\"\n",
    "y_train = train['class']\n",
    "y_test = test['class']\n",
    "X_train = train.drop(columns='class')\n",
    "X_test = test.drop(columns='class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7p1Nn0WmDIjI"
   },
   "outputs": [],
   "source": [
    "# d) Scale all features / predictors (NOT THE TARGET VARIABLE)\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_scaled = pd.DataFrame(scaler.transform(X_train))\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YnVXipcJQEcy"
   },
   "outputs": [],
   "source": [
    "#update column names of the X dataframes\n",
    "X_train_scaled.columns = X_train.columns.values\n",
    "X_test_scaled.columns = X_test.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rR2Npi37WvuI"
   },
   "source": [
    "**2. Random Forest Classifier - Base Model:**\n",
    "\n",
    "Start by creating a simple Random Forest only using default parameters - this will let us compare SVMs to Random Forest in multiclass problems.\n",
    "\n",
    "a) Use the RandomForestClassifier in sklearn. Fit your model on the training data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3SLSY7XGWmtV"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RFC = RandomForestClassifier()\n",
    "base_model = RFC.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jk_kcS9QXmro"
   },
   "source": [
    "b) Use the fitted model to predict on test data. Use the .predict() method to get the predicted classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uABApE3OXfL6"
   },
   "outputs": [],
   "source": [
    "y_pred_base = base_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gAU9iHXBX9NM"
   },
   "source": [
    "c) Calculate the confusion matrix and classification report (both are in sklearn.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "vSznxhkEXmae",
    "outputId": "53541036-d7e0-40f3-a7f6-847935a9a9ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[14  0  0  0  0  0  0  0  0]\n",
      " [ 1 20  1  3  0  0  0  0  0]\n",
      " [ 0  3 11  1  0  0  0  0  0]\n",
      " [ 0  4  0 19  0  0  0  0  0]\n",
      " [ 0  0  0  0 23  0  0  0  6]\n",
      " [ 1  0  1  0  0 13  0  0  0]\n",
      " [ 2  0  0  0  0  0 14  0  0]\n",
      " [ 0  2  0  5  3  0  0  4  0]\n",
      " [ 0  0  0  1  2  0  0  0 14]]\n"
     ]
    }
   ],
   "source": [
    "#Calculate and print confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred_base)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "kfzmixb4Z9Dm",
    "outputId": "20b3e009-dc4c-46c8-fa63-9517a5835004"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   asphalt        0.78      1.00      0.88        14\n",
      "  building        0.69      0.80      0.74        25\n",
      "       car        0.85      0.73      0.79        15\n",
      "  concrete        0.66      0.83      0.73        23\n",
      "     grass        0.82      0.79      0.81        29\n",
      "      pool        1.00      0.87      0.93        15\n",
      "    shadow        1.00      0.88      0.93        16\n",
      "      soil        1.00      0.29      0.44        14\n",
      "      tree        0.70      0.82      0.76        17\n",
      "\n",
      "avg / total       0.81      0.79      0.78       168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print classification report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_base))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dSzWS5R8dJgg"
   },
   "source": [
    "d) Identify the top 5 features. Feel free to print a list OR to make a plot. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "oS_gDkJBdGtT",
    "outputId": "67287b5c-f79b-43c5-8b80-006bcdf02340"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean_R_40</th>\n",
       "      <td>0.069445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean_R_80</th>\n",
       "      <td>0.046583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bright</th>\n",
       "      <td>0.043644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDVI</th>\n",
       "      <td>0.042169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean_NIR_40</th>\n",
       "      <td>0.040844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Feature Importance\n",
       "Mean_R_40              0.069445\n",
       "Mean_R_80              0.046583\n",
       "Bright                 0.043644\n",
       "NDVI                   0.042169\n",
       "Mean_NIR_40            0.040844"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "feature_imp = pd.DataFrame(base_model.feature_importances_) \n",
    "feature_imp.set_index(X_train.columns.values)\n",
    "feature_imp = feature_imp.rename(index=lambda x: X_train.columns[x])\n",
    "feature_imp.columns = ['Feature Importance']\n",
    "feature_imp.sort_values('Feature Importance',ascending=False).head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "514fS_-D9w_u"
   },
   "source": [
    "The base model does a pretty good job in general of predicting the class, but as we can see some classes such as  building are performing much lower than the others. We will see if another model is able to improve this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DIaVF5JzdRPa"
   },
   "source": [
    "**3. LinearSVM Classifier - Base Model:**\n",
    "\n",
    "Create a simple LinearSVC Classifier only using default parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "7fbGleY1c_HQ",
    "outputId": "9d0e7af5-49df-490b-900f-60034a001e52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[13  0  0  0  0  0  1  0  0]\n",
      " [ 0 22  1  1  1  0  0  0  0]\n",
      " [ 0  2 12  0  0  0  0  0  1]\n",
      " [ 1  6  0 15  0  0  0  0  1]\n",
      " [ 0  0  0  1 26  0  0  0  2]\n",
      " [ 1  0  1  0  0 13  0  0  0]\n",
      " [ 2  0  0  0  0  0 14  0  0]\n",
      " [ 0  4  0  1  3  0  0  6  0]\n",
      " [ 0  0  0  1  6  0  0  0 10]]\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   asphalt        0.76      0.93      0.84        14\n",
      "  building        0.65      0.88      0.75        25\n",
      "       car        0.86      0.80      0.83        15\n",
      "  concrete        0.79      0.65      0.71        23\n",
      "     grass        0.72      0.90      0.80        29\n",
      "      pool        1.00      0.87      0.93        15\n",
      "    shadow        0.93      0.88      0.90        16\n",
      "      soil        1.00      0.43      0.60        14\n",
      "      tree        0.71      0.59      0.65        17\n",
      "\n",
      "avg / total       0.80      0.78      0.77       168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#a) Use the LinearSVC in sklearn. Fit your model on the training data.\n",
    "from sklearn.svm import LinearSVC\n",
    "LSVC = LinearSVC()\n",
    "LSVC_model = LSVC.fit(X_train_scaled, y_train)\n",
    "\n",
    "#b) Use the fitted model to predict on test data. Use the .predict() method to get the predicted classes.\n",
    "y_pred_SVC = LSVC_model.predict(X_test_scaled)\n",
    "\n",
    "#c) Calculate the confusion matrix and classification report (both are in sklearn.metrics).\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_SVC))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_SVC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "khIChMsmfUaj"
   },
   "source": [
    "**4. Support Vector Machine Classifier + Linear Kernel + Grid Search:**\n",
    "\n",
    "We will now use GridSearchCV to try various hyperparameters in a SVM with linear kernel.\n",
    "\n",
    "a) Use SVC from sklearn with kernel = \"linear\". Run the GridSearchCV using the following (SVMs run much faster than RandomForest):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4piRTyhWerYw"
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "SVC = svm.SVC(kernel = 'linear')\n",
    "param_grid = {'C': np.arange(0.01,10.0,0.2) }\n",
    "GSVC = GridSearchCV(SVC, param_grid, cv=5)\n",
    "GSVC_fit = GSVC.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m2qUDWznxXQ4"
   },
   "source": [
    "b) Identify the best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ud66R9zMw9V0",
    "outputId": "ec11d3e7-db38-4b2a-9efc-3125b9795ba2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.01}"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This method outputs to best performing parameters\n",
    "GSVC_fit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "s-LdPz8OxQyb",
    "outputId": "e4234e4e-0cbe-4f3e-f4d3-8cfdb169737e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.01, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This method outputs the best performing model, and can be used for predicting on the X_test\n",
    "GSVC_fit.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5_rgHVNS2eAy"
   },
   "source": [
    "c) Use the best estimator model to predict on test data. Use the .predict() method to get the predicted classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HJUxcdpf1rjn"
   },
   "outputs": [],
   "source": [
    "GSVC_pred = GSVC_fit.best_estimator_.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZAjO_DG32gkA"
   },
   "source": [
    "d) Calculate the confusion matrix and classification report (both are in sklearn.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "YXiGoqps2msk",
    "outputId": "0ab091ad-1b80-4ffc-a26c-e3110512a36a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[13  0  0  0  0  0  1  0  0]\n",
      " [ 0 22  0  2  1  0  0  0  0]\n",
      " [ 0  1 14  0  0  0  0  0  0]\n",
      " [ 0  5  0 17  0  0  0  1  0]\n",
      " [ 0  0  0  1 25  0  0  0  3]\n",
      " [ 0  0  0  0  0 14  1  0  0]\n",
      " [ 1  0  0  0  0  0 15  0  0]\n",
      " [ 0  3  0  5  2  0  0  4  0]\n",
      " [ 0  0  0  1  2  0  0  0 14]]\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   asphalt        0.93      0.93      0.93        14\n",
      "  building        0.71      0.88      0.79        25\n",
      "       car        1.00      0.93      0.97        15\n",
      "  concrete        0.65      0.74      0.69        23\n",
      "     grass        0.83      0.86      0.85        29\n",
      "      pool        1.00      0.93      0.97        15\n",
      "    shadow        0.88      0.94      0.91        16\n",
      "      soil        0.80      0.29      0.42        14\n",
      "      tree        0.82      0.82      0.82        17\n",
      "\n",
      "avg / total       0.83      0.82      0.81       168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, GSVC_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, GSVC_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p2HTxmiU25ZG"
   },
   "source": [
    "**5. Support Vector Machine Classifier + Polynomial Kernel + Grid Search:**\n",
    "\n",
    "We will now use GridSearchCV to try various hyperparameters in a SVM with a polynomial kernel.\n",
    "\n",
    "a) Use SVC from sklearn with kernel = \"poly\". Run the GridSearchCV using the following:\n",
    "\n",
    "C: 0.01 - 10 in increments of 0.2\n",
    "\n",
    "degree: 2, 3, 4, 5, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e7EbteTI20H1"
   },
   "outputs": [],
   "source": [
    "SVC = svm.SVC(kernel = 'linear')\n",
    "param_grid = {'C': np.arange(0.01,10.0,0.2) ,'degree':[2,3,4,5,6]}\n",
    "GSVC_poly = GridSearchCV(SVC, param_grid, cv=5)\n",
    "GSVC_poly_fit = GSVC.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bfHnYPYa320g"
   },
   "source": [
    "b) Identify the best performing model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "M59pHAc03z5R",
    "outputId": "767bdce4-21a6-4aec-f63f-af76928e2252"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01}\n",
      "SVC(C=0.01, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "#This method outputs to best performing parameters\n",
    "print(GSVC_poly_fit.best_params_)\n",
    "#This method outputs the best performing model, and can be used for predicting on the X_test\n",
    "print(GSVC_poly_fit.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P5o8F1bZ4eQA"
   },
   "source": [
    "c) Use the best estimator model to predict on test data. Use the .predict() method to get the predicted classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cib-2Qqp4ese"
   },
   "outputs": [],
   "source": [
    "GSVC_poly_pred = GSVC_fit.best_estimator_.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tAqnofxU4kfU"
   },
   "source": [
    "d) Calculate the confusion matrix and classification report (both are in sklearn.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "uF3SszAA4rDa",
    "outputId": "5de756ae-447f-43d9-bbca-42608838c9b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[13  0  0  0  0  0  1  0  0]\n",
      " [ 0 22  0  2  1  0  0  0  0]\n",
      " [ 0  1 14  0  0  0  0  0  0]\n",
      " [ 0  5  0 17  0  0  0  1  0]\n",
      " [ 0  0  0  1 25  0  0  0  3]\n",
      " [ 0  0  0  0  0 14  1  0  0]\n",
      " [ 1  0  0  0  0  0 15  0  0]\n",
      " [ 0  3  0  5  2  0  0  4  0]\n",
      " [ 0  0  0  1  2  0  0  0 14]]\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   asphalt        0.93      0.93      0.93        14\n",
      "  building        0.71      0.88      0.79        25\n",
      "       car        1.00      0.93      0.97        15\n",
      "  concrete        0.65      0.74      0.69        23\n",
      "     grass        0.83      0.86      0.85        29\n",
      "      pool        1.00      0.93      0.97        15\n",
      "    shadow        0.88      0.94      0.91        16\n",
      "      soil        0.80      0.29      0.42        14\n",
      "      tree        0.82      0.82      0.82        17\n",
      "\n",
      "avg / total       0.83      0.82      0.81       168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, GSVC_poly_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, GSVC_poly_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AxZOXtbc5A5g"
   },
   "source": [
    "**6. Support Vector Machine Classifier + RBF Kernel + Grid Search:**\n",
    "\n",
    "We will now use GridSearchCV to try various hyperparameters in a SVM with a RBF kernel.\n",
    "\n",
    "a) Use SVC from sklearn with kernel = \"rbf\". Run the GridSearchCV using the following:\n",
    "\n",
    "C: 0.01 - 10 in increments of 0.2\n",
    "gamma: 0.1, 1, 10, 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WeE-dL875Ffc"
   },
   "outputs": [],
   "source": [
    "SVC = svm.SVC(kernel = 'rbf')\n",
    "param_grid = {'C': np.arange(0.01,10.0,0.2) ,'gamma':[0.001,0.01,0.1,1,10,100]}\n",
    "GSVC_poly = GridSearchCV(SVC, param_grid, cv=5)\n",
    "GSVC_poly_fit = GSVC.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZjjqoK3t5m2c"
   },
   "source": [
    "b) Identify the best performing model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "2juRD20C5nHf",
    "outputId": "43f65774-e5dd-4fc0-b742-36af4aea0825"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01}\n",
      "SVC(C=0.01, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "#This method outputs to best performing parameters\n",
    "print(GSVC_poly_fit.best_params_)\n",
    "#This method outputs the best performing model, and can be used for predicting on the X_test\n",
    "print(GSVC_poly_fit.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "Aa52t65i5raT",
    "outputId": "5e94eca1-cc22-4de4-bf60-8dae5d5f4a30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[13  0  0  0  0  0  1  0  0]\n",
      " [ 0 22  0  2  1  0  0  0  0]\n",
      " [ 0  1 14  0  0  0  0  0  0]\n",
      " [ 0  5  0 17  0  0  0  1  0]\n",
      " [ 0  0  0  1 25  0  0  0  3]\n",
      " [ 0  0  0  0  0 14  1  0  0]\n",
      " [ 1  0  0  0  0  0 15  0  0]\n",
      " [ 0  3  0  5  2  0  0  4  0]\n",
      " [ 0  0  0  1  2  0  0  0 14]]\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   asphalt        0.93      0.93      0.93        14\n",
      "  building        0.71      0.88      0.79        25\n",
      "       car        1.00      0.93      0.97        15\n",
      "  concrete        0.65      0.74      0.69        23\n",
      "     grass        0.83      0.86      0.85        29\n",
      "      pool        1.00      0.93      0.97        15\n",
      "    shadow        0.88      0.94      0.91        16\n",
      "      soil        0.80      0.29      0.42        14\n",
      "      tree        0.82      0.82      0.82        17\n",
      "\n",
      "avg / total       0.83      0.82      0.81       168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#c) Use the best estimator model to predict on test data. Use the .predict() method to get the predicted classes.\n",
    "GSVC_rbf_pred = GSVC_fit.best_estimator_.predict(X_test_scaled)\n",
    "\n",
    "#d) Calculate the confusion matrix and classification report (both are in sklearn.metrics)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, GSVC_poly_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, GSVC_poly_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CjbRkpvd58ax"
   },
   "source": [
    "**7. From the models run in steps 2-6, which performs the best based on the Classification Report? Support your reasoning with evidence around your test data. **\n",
    "\n",
    "Th best model is model 4 (Support Vector Machine Classifier + Linear Kernel + Grid Search)\n",
    "\n",
    "I chose this model because it has a higher average precision and recall percentage than the base models. Models 4-6 have the same overall precision and recall which is why I chose model 4 because it has the simplest kernel and has less of a chance of overfitting the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oTOOmnxD6CKC"
   },
   "source": [
    "**8. Compare models run for steps 4-6 where different kernels were used. What is the benefit of using a polynomial or rbf kernel over a linear kernel? What could be a downside of using a polynomial or rbf kernel? **\n",
    "\n",
    "Kernels allow us to enhance the feature space using a transformation \n",
    "\n",
    "One downside of using a polynomial or rbf kernel is that it increases the chance of overfitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V655O0z46HR7"
   },
   "source": [
    "**9. Explain the 'C' parameter used in steps 4-6. What does a small C mean versus a large C in sklearn? Why is it important to use the 'C' parameter when fitting a model? **\n",
    "\n",
    "The C parameter determines the sensitivity of the model to misclassification. A smaller C value will represent a less strict model that allows for some misclassification, but using a larger C will cause tight margins and may result in the model to overfitting the data.\n",
    "\n",
    "It is important to use the C parameter to help produce a generalizable model that will not overfit the train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0vH50bDe6LXd"
   },
   "source": [
    "**10. It is also important to check for overfitting: For your best performing model provide metrics for the training and test sets and explain whether your model is overfitting the data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "uQ1ugitK6P56",
    "outputId": "9c0a600c-49f3-4576-94d9-f938f5b0d717"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:              precision    recall  f1-score   support\n",
      "\n",
      "   asphalt        0.93      0.93      0.93        14\n",
      "  building        0.71      0.88      0.79        25\n",
      "       car        1.00      0.93      0.97        15\n",
      "  concrete        0.65      0.74      0.69        23\n",
      "     grass        0.83      0.86      0.85        29\n",
      "      pool        1.00      0.93      0.97        15\n",
      "    shadow        0.88      0.94      0.91        16\n",
      "      soil        0.80      0.29      0.42        14\n",
      "      tree        0.82      0.82      0.82        17\n",
      "\n",
      "avg / total       0.83      0.82      0.81       168\n",
      " Train:              precision    recall  f1-score   support\n",
      "\n",
      "   asphalt        0.93      0.89      0.91        45\n",
      "  building        0.85      0.90      0.87        97\n",
      "       car        1.00      0.90      0.95        21\n",
      "  concrete        0.87      0.89      0.88        93\n",
      "     grass        0.91      0.84      0.88        83\n",
      "      pool        1.00      0.86      0.92        14\n",
      "    shadow        0.86      0.96      0.91        45\n",
      "      soil        1.00      0.55      0.71        20\n",
      "      tree        0.87      0.96      0.91        89\n",
      "\n",
      "avg / total       0.89      0.89      0.89       507\n",
      "\n"
     ]
    }
   ],
   "source": [
    "GSVC_pred_train = GSVC_fit.best_estimator_.predict(X_train_scaled)\n",
    "print(\"Test:\",classification_report(y_test, GSVC_pred),\"Train:\",classification_report(y_train, GSVC_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gZhmAas0ro0H"
   },
   "source": [
    "As we can see the precision and the recall percentages do not vary significantly from the train to the test data. This implies the model generalizable and is not overfitting the test data."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment 5.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
